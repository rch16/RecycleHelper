{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "CR3Pl6gxeIWw",
    "outputId": "ded59804-c6c8-43ee-fc7b-48d557e2d0ec"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras\n",
    "import zipfile as zf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.layers import InputLayer, Conv2D, MaxPooling2D, Dense, Dropout, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Ok2boA5eIW3"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y65MmEQ_eIW5"
   },
   "source": [
    "The following helper functions were written by Collin Ching for his post \"How to build an image classifier for waste sorting\"\n",
    "\n",
    "article : https://towardsdatascience.com/how-to-build-an-image-classifier-for-waste-sorting-6d11d3c9c478\n",
    "\n",
    "python notebook : https://nbviewer.jupyter.org/github/collindching/Waste-Sorter/blob/master/Waste%20sorter.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mdSLD_reIW6"
   },
   "outputs": [],
   "source": [
    "# splits indices for a folder into train, validation, and test indices with random sampling   \n",
    "def split_indices(folder,seed1,seed2):    \n",
    "    n = len(os.listdir(folder))\n",
    "    full_set = list(range(1,n+1))\n",
    "\n",
    "    ## train indices\n",
    "    random.seed(seed1)\n",
    "    train = random.sample(list(range(1,n+1)),int(.5*n))\n",
    "\n",
    "    ## temp\n",
    "    remain = list(set(full_set)-set(train))\n",
    "\n",
    "    ## separate remaining into validation and test\n",
    "    random.seed(seed2)\n",
    "    valid = random.sample(remain,int(.5*len(remain)))\n",
    "    test = list(set(remain)-set(valid))\n",
    "    \n",
    "    return(train,valid,test)\n",
    "\n",
    "# gets file names for a particular type of trash, given indices\n",
    "def get_names(waste_type,indices):\n",
    "    file_names = [waste_type+str(i)+\".jpg\" for i in indices]\n",
    "    return(file_names)    \n",
    "\n",
    "# moves group of source files to another folder\n",
    "def move_files(source_files,destination_folder):\n",
    "    for file in source_files:\n",
    "        shutil.move(file,destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xem8-tA4eIW-"
   },
   "outputs": [],
   "source": [
    "def create_directory(): \n",
    "    # paths will be train/cardboard, train/glass, etc...\n",
    "    subsets = ['train','valid']\n",
    "    waste_types = ['cardboard','glass','metal','paper','plastic','trash']\n",
    "\n",
    "    # create destination folders for data subset and waste type\n",
    "    for subset in subsets:\n",
    "        for waste_type in waste_types:\n",
    "            folder = os.path.join(data_path,subset,waste_type)\n",
    "            if not os.path.exists(folder):\n",
    "                os.makedirs(folder)\n",
    "\n",
    "    if not os.path.exists(os.path.join(data_path,'test')):\n",
    "        os.makedirs(os.path.join(data_path,'test'))\n",
    "\n",
    "    # move files to destination folders for each waste type\n",
    "    for waste_type in waste_types:\n",
    "        source_folder = os.path.join(path,waste_type)\n",
    "        train_ind, valid_ind, test_ind = split_indices(source_folder,1,1)\n",
    "\n",
    "        # move source files to train\n",
    "        train_names = get_names(waste_type,train_ind)\n",
    "        train_source_files = [os.path.join(source_folder,name) for name in train_names]\n",
    "        train_dest = train_path+\"/\"+waste_type\n",
    "        move_files(train_source_files,train_dest)\n",
    "\n",
    "        # move source files to valid\n",
    "        valid_names = get_names(waste_type,valid_ind)\n",
    "        valid_source_files = [os.path.join(source_folder,name) for name in valid_names]\n",
    "        valid_dest = valid_path+\"/\"+waste_type\n",
    "        move_files(valid_source_files,valid_dest)\n",
    "\n",
    "        # move source files to test\n",
    "        test_names = get_names(waste_type,test_ind)\n",
    "        test_source_files = [os.path.join(source_folder,name) for name in test_names]\n",
    "\n",
    "        # I use data/test here because the images can be mixed up\n",
    "        move_files(test_source_files,test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rImgeG8deIXD"
   },
   "outputs": [],
   "source": [
    "def createFileList(myDir, format='.jpg'):\n",
    "    fileList = []\n",
    "    print(myDir)\n",
    "    for root, dirs, files in os.walk(myDir, topdown=False):\n",
    "        for name in files:\n",
    "            if name.endswith(format):\n",
    "                fullName = os.path.join(root, name)\n",
    "                fileList.append(fullName)\n",
    "    return fileList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80Gv91ymeIXI"
   },
   "source": [
    "End of Collin's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Sc6h2NreIXI"
   },
   "outputs": [],
   "source": [
    "def stringContains(filePath):\n",
    "    if \"paper\" in filePath:\n",
    "        return 0\n",
    "    elif \"cardboard\" in filePath:\n",
    "        return 1\n",
    "    elif \"trash\" in filePath:\n",
    "        return 2\n",
    "    elif \"plastic\" in filePath:\n",
    "        return 3\n",
    "    elif \"metal\" in filePath:\n",
    "        return 4\n",
    "    elif \"glass\" in filePath:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "\n",
    "def convertToMatrix(fileList,num_images):\n",
    "    \n",
    "    num_pixels = 196608\n",
    "    data = np.empty((num_images,num_pixels))\n",
    "    labels = []\n",
    "    label_count = [0,0,0,0,0,0,0]\n",
    "    index = 0\n",
    "    \n",
    "    for file in fileList:\n",
    "        \n",
    "        img = Image.open(file) # open image\n",
    "        arr = np.array(img.convert('L')) # convert to grey and place in numpy array\n",
    "        vec = arr.ravel() # flatten to vector\n",
    "        data[index,:] = vec.T # add to matrix\n",
    "        \n",
    "        name = stringContains(img.filename) # get image name\n",
    "        labels = np.append(labels,name) # add to array\n",
    "        label_count[name] += 1\n",
    "        \n",
    "        index += 1\n",
    "\n",
    "    return data, labels, label_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AJd0al0veIXQ"
   },
   "source": [
    "## Import Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-j4eJTreIXQ"
   },
   "outputs": [],
   "source": [
    "path = \"dataset-resized\"\n",
    "data_path = \"/data\"\n",
    "test_path = \"/data/test\"\n",
    "train_path = \"/data/train\"\n",
    "valid_path = \"/data/valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C7QhIZ0cekTw",
    "outputId": "a95de30f-76a4-423e-8530-c03e9dbdc16a"
   },
   "outputs": [],
   "source": [
    "files = zf.ZipFile(\"dataset-resized.zip\",'r')\n",
    "files.extractall()\n",
    "files.close()\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kum8ggibgACV",
    "outputId": "70db900b-7be9-48b6-b5d9-f2b54eb96456"
   },
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(os.getcwd(),\"dataset-resized\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVHAYFqAeIXe"
   },
   "outputs": [],
   "source": [
    "create_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "EWZTWyV6eIXj",
    "outputId": "66320765-3434-46dc-8e2a-794394e165a2"
   },
   "outputs": [],
   "source": [
    "train_files = createFileList(train_path,format='.jpg')\n",
    "test_files = createFileList(test_path,format='.jpg')\n",
    "valid_files = createFileList(valid_path,format='.jpg')\n",
    "fileList = createFileList(path,format='.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "KOVlKv5reIXo",
    "outputId": "494ee2e1-274b-41ba-edd4-9524e5bb2c20"
   },
   "outputs": [],
   "source": [
    "print(len(train_files), \"training images\")\n",
    "print(len(test_files), \"testing images\")\n",
    "print(len(valid_files), \"validation images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhKbEW0reIXr"
   },
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n25oMauveIXr"
   },
   "source": [
    "Convert images to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "HuCethooeIXs",
    "outputId": "5cc30407-55f3-45df-cc76-a100101370d3"
   },
   "outputs": [],
   "source": [
    "train,train_l,train_count = convertToMatrix(train_files,1262)\n",
    "test,test_l,test_count = convertToMatrix(test_files,635)\n",
    "valid,valid_l,valid_count = convertToMatrix(valid_files,630)\n",
    "\n",
    "train = train.astype('float32')\n",
    "train_l = train_l.astype('uint8')\n",
    "test = test.astype('float32')\n",
    "test_l = test_l.astype('uint8')\n",
    "valid = valid.astype('float32')\n",
    "valid_l = valid_l.astype('uint8')\n",
    "\n",
    "print(\"data\")\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(valid.shape)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"labels\")\n",
    "print(train_l.shape)\n",
    "print(test_l.shape)\n",
    "print(valid_l.shape)\n",
    "\n",
    "print(\"\")\n",
    "print(\"count\")\n",
    "print(train_count)\n",
    "print(test_count)\n",
    "print(valid_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "colab_type": "code",
    "id": "RUuF9zv-eIXu",
    "outputId": "b3d2e3c6-0a6e-4ae2-ab8c-15c8a5fed251"
   },
   "outputs": [],
   "source": [
    "class_names = ['paper', 'cardboard', 'trash', 'plastic', 'metal','glass']\n",
    "\n",
    "random_idx = []\n",
    "for i in range(25):\n",
    "    random.seed(i)\n",
    "    random_idx.append(random.randrange(0,1262))\n",
    "    \n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    \n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    \n",
    "    idx = random_idx[i]\n",
    "    image = train[idx].reshape((384,512))\n",
    "    plt.imshow(image)\n",
    "    plt.xlabel(class_names[train_l[idx]])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMJb5EC0eIXz"
   },
   "source": [
    "Convert labels to one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "rl5i3AvweIXz",
    "outputId": "0a771aaf-6b29-46c7-c569-bc4c9cf8c653"
   },
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_l).astype('uint8')\n",
    "test_labels = to_categorical(test_l).astype('uint8')\n",
    "valid_labels = to_categorical(valid_l).astype('uint8')\n",
    "\n",
    "print(\"Labels:\")\n",
    "print(\"train\", train_l.shape)\n",
    "print(\"test\", test_l.shape)\n",
    "print(\"validate\", valid_l.shape)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"One Hot Encoded Labels:\")\n",
    "print(\"train\", train_labels.shape)\n",
    "print(\"test\", test_labels.shape)\n",
    "print(\"validate\", valid_labels.shape)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(train_l[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ommZUFtleIX2"
   },
   "source": [
    "Reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P4WSrOJreIX3"
   },
   "outputs": [],
   "source": [
    "rows = 384\n",
    "cols = 512\n",
    "\n",
    "## channel last configuration\n",
    "train_data = train.reshape(train.shape[0],rows,cols,1)\n",
    "test_data = test.reshape(test.shape[0],rows,cols,1)\n",
    "valid_data = valid.reshape(valid.shape[0],rows,cols,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tP2BGcLXeIX6"
   },
   "source": [
    "Normalise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "kdfq19D0eIX6",
    "outputId": "7c1c42c9-ffa7-4f17-885f-a2ae422acb19"
   },
   "outputs": [],
   "source": [
    "train_data /= 255.0\n",
    "test_data /= 255.0\n",
    "valid_data /= 255.0\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(valid_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VHN7hte5eIYE"
   },
   "source": [
    "## CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zSwN3ViaeIYF"
   },
   "outputs": [],
   "source": [
    "# input data\n",
    "n_classes = 6\n",
    "rows = 384\n",
    "cols = 512\n",
    "input_shape = (rows,cols,1)\n",
    "class_weights = {0: 7,\n",
    "                 1: 10,\n",
    "                 2: 30,\n",
    "                 3: 8,\n",
    "                 4: 10,\n",
    "                 5: 8}\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 75\n",
    "epochs = 200\n",
    "dropout_prob = 0.5\n",
    "lr = 0.01\n",
    "m = 0.0\n",
    "\n",
    "# model architecture\n",
    "opt = tensorflow.keras.optimizers.SGD(learning_rate=lr, momentum=m)\n",
    "pool_size = 2\n",
    "num_filters1 = 32\n",
    "num_filters2 = 64\n",
    "num_filters3 = 128\n",
    "filter_size = 5\n",
    "filter_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yAD4B8ek2eI5"
   },
   "outputs": [],
   "source": [
    "p = {'lr': (0.001,0.01,0.1),\n",
    "     'batch_size': (50,75,100),\n",
    "     'epochs': (50,100,200),\n",
    "     'dropout': (0,0.2,1),\n",
    "     'mom': (0.0,0.2,0.4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lnOALtOqeIYG"
   },
   "outputs": [],
   "source": [
    "def waste_classifier_model_talos(x_train,y_train,x_val,y_val,params): \n",
    "    model = Sequential() #name=\"Waste Classifier Model 2\")\n",
    "\n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "\n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Conv2D(num_filters1,filter_size,activation='relu',data_format=\"channels_last\"))#,input_shape=input_shape,))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    \n",
    "    model.add(Conv2D(num_filters2,filter_size, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # the output softmax layer will have one node for each class\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes,activation='softmax'))\n",
    "    \n",
    "    opt = tensorflow.keras.optimizers.SGD(learning_rate=params['lr'], momentum=params['mom'])\n",
    "    model.compile(loss='mse',optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    output = model.fit(x_train,y_train,batch_size=params['batch_size'],epochs=params['epochs'],class_weight=class_weights,validation_data=[x_val,y_val])\n",
    "\n",
    "    return output, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "gYT-Bs9w3mb7",
    "outputId": "a3ab3818-4a40-4daf-835c-cdd775240cf1"
   },
   "outputs": [],
   "source": [
    "scan_object = talos.Scan(train_data,\n",
    "                         train_labels,\n",
    "                         params=p,\n",
    "                         model=waste_classifier_model_talos,\n",
    "                         experiment_name='waste_classifier',\n",
    "                         fraction_limit=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QP3qNq0zDyYX"
   },
   "outputs": [],
   "source": [
    "def waste_classifier_model(): \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "\n",
    "    model.add(Conv2D(num_filters1,filter_size,activation='relu',data_format=\"channels_last\"))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    \n",
    "    model.add(Conv2D(num_filters2,filter_size, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # the output softmax layer will have one node for each class\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes,activation='softmax'))\n",
    "    \n",
    "    opt = tensorflow.keras.optimizers.SGD(learning_rate=lr, momentum=m)\n",
    "    model.compile(loss='mse',optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "i48y3jKZeIYI",
    "outputId": "96341129-c3dd-4a19-84c1-39d3259f53a0"
   },
   "outputs": [],
   "source": [
    "# K.clear_session()\n",
    "# waste_model = waste_classifier_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6FCc7mdBeIYQ"
   },
   "source": [
    "Convert to tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Xv0-H0nieIYQ",
    "outputId": "ac921644-8038-4a79-f16b-a4469fcd35f4"
   },
   "outputs": [],
   "source": [
    "# train_dataset = Dataset.from_tensor_slices((train_data, train_labels))\n",
    "# test_dataset = Dataset.from_tensor_slices((test_data, test_labels))\n",
    "# valid_dataset = Dataset.from_tensor_slices((valid_data, valid_labels))\n",
    "\n",
    "# train_dataset = train_dataset.batch(batch_size)\n",
    "# test_dataset = test_dataset.batch(batch_size)\n",
    "# valid_dataset = valid_dataset.batch(batch_size)\n",
    "\n",
    "# print(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8UqJ03SveIYS",
    "outputId": "9eb96038-1edb-42f5-f4a5-6457adb8c6c2"
   },
   "outputs": [],
   "source": [
    "# waste_model.fit(train_dataset.shuffle(3000),\n",
    "#                 class_weight=class_weights,\n",
    "#                 epochs=epochs,\n",
    "#                 verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8FS89kaeIYV"
   },
   "outputs": [],
   "source": [
    "# test_loss, test_acc = waste_model.evaluate(test_dataset)\n",
    "\n",
    "# print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bsnf08QweIYW"
   },
   "outputs": [],
   "source": [
    "# print(test_dataset)\n",
    "# predictions = waste_model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OiwOy61Rgy7g"
   },
   "outputs": [],
   "source": [
    "# print(predictions.shape)\n",
    "\n",
    "# print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-ekfzdDhAva"
   },
   "outputs": [],
   "source": [
    "# class_labels = ['paper', 'cardboard', 'trash', 'plastic', 'metal', 'glass']\n",
    "# matrix = confusion_matrix(test_labels.argmax(axis=1), predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-_R-FO1iFEq"
   },
   "outputs": [],
   "source": [
    "# print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCJ3WE9ThK6d"
   },
   "outputs": [],
   "source": [
    "# print('Confusion Matrix')\n",
    "# print(matrix)\n",
    "# print('Classification Report')\n",
    "# print(classification_report(test_labels.argmax(axis=1), predictions.argmax(axis=1), target_names=class_labels))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "wasteclassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
